{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project n° 2 – Conditional VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listes des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les définir + justifier les valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "beta = 1\n",
    "kl_weights = [1, 10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='../../data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='../../data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un modèle d'AutoEndodeur Variationnel Conditionnel (Conditionnal VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle de VAE conditionnel utilisé par la suite se construit de la manière suivante :\n",
    "\n",
    "- **Un Encodeur** : \n",
    "    - Une couche de convolution composée de 32 filtres, un noyau de taille 4, un stride de 2 and un padding de 1.\n",
    "    - Une couche BatchNorm qui conserve le même nombre de caractérstiques.\n",
    "    - Une fonction d'activation ReLu.\n",
    "    - Une couche de convolution composée de 64 filtres, un noyau de taille 4, un stride de 2 and un padding de 1.\n",
    "    - Une couche BatchNorm qui conserve le même nombre de caractérstiques.\n",
    "    - Une fonction d'activation ReLu.\n",
    "    - Une couche de convolution composée de 128 filtres, un noyau de taille 3, un stride de 2 and un padding de 1..\n",
    "    - Une couche BatchNorm qui conserve le même nombre de caractérstiques.\n",
    "    - Une fonction d'activation ReLu.\n",
    "\n",
    "- **Un espace latent** :\n",
    "\n",
    "- **Un Décodeur.** \n",
    "    - Une couche de déconvolution composée de 64 filtres, un noyau de taille 3, un stride de 2 and un padding de 1.\n",
    "    - Une couche BatchNorm qui conserve le même nombre de caractérstiques\n",
    "    - Une fonction d'activation ReLu\n",
    "    - Une couche de déconvolution composée de 32 filtres, un noyau de taille 4, un stride de 2 and un padding de 1.\n",
    "    - Une couche BatchNorm qui conserve le même nombre de caractérstiques\n",
    "    - Une fonction d'activation ReLu\n",
    "    - Une couche de déconvolution composée de 1 filtre, un noyau de taille 4, un stride de 2 and un padding de 1.\n",
    "    - Une fonction d'activation Sigmoïde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir ce qu'est/ le rôle : noyau, stride, padding, fonction d'activation, espace latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c sera à expliciter = condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=10):\n",
    "        super(ConvVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),  # Output: (32, 14, 14)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # Output: (64, 7, 7)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # Output: (128, 4, 4)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Fully connected layers for mean and log variance\n",
    "        self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim) # (128*4*4) est la taille de sortie de la couche précédente\n",
    "        self.fc_logvar = nn.Linear(128 * 4 * 4, latent_dim) \n",
    "        self.fc_decode = nn.Linear(latent_dim, 128 * 4 * 4) \n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1),  # Output: (64, 8, 8)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # Output: (32, 16, 16)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),  # Output: (1, 28, 28)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x,c ):\n",
    "        x = self.encoder(x)\n",
    "        x = torch.cat((x,c),dim=1)\n",
    "        x = x.view(-1, 128 * 4 * 4) # Flatten the output of the convolutional layers\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "\n",
    "    def latent_sample(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z, c):\n",
    "        x = torch.cat((x,c),dim=1)\n",
    "        x = self.fc_decode(z)\n",
    "        x = x.view(-1, 128, 4, 4)  # Reshape to (128, 4, 4) for the decoder\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        mu, logvar = self.encode(x, c)\n",
    "        z = self.latent_sample(mu, logvar)\n",
    "        return self.decode(z, c), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la fonction de perte (loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar, beta=1):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum') # terme de reconstruction \n",
    "    # on utilise binary entropy pour forcer les contrastes (sinon on pourrait travailler avec MSE)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # terme de regularisation (on veut se rapprocher loi normale)\n",
    "    return BCE + beta * KLD # l'objectif est d'avoir un bon compromis entre reconstruction et regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle de VAE conditionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VAE model and the Adam optimizer\n",
    "vae = ConvVAE(latent_dim=latent_dim)\n",
    "vae.to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model for the given number of epochs\n",
    "# At the end of each epoch, print the training loss\n",
    "for epoch in range(1, epochs + 1):\n",
    "    vae.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch}, Training loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sample(num_samples=10, digit):\n",
    "# digit est la valeur conditionelle\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Échantillonage selon une loi normale\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)  # Sample random latent vectors\n",
    "\n",
    "        # On ajoute la condition ie la valeur que l'on veut générer\n",
    "        condition = torch.zeros(100,10, dtype=int)\n",
    "        condition[:,digit] = 1 # indique que c'est la valeur digit que l'on cherche à générer\n",
    "\n",
    "        # On génère l'image\n",
    "        samples = vae.decode(z, condition) # Decode the latent vectors\n",
    "        samples = samples.cpu().view(num_samples, 1, 28, 28) # Reshape the samples\n",
    "\n",
    "        fig, ax = plt.subplots(1, num_samples, figsize=(15, 2))\n",
    "        for i in range(num_samples):\n",
    "            ax[i].imshow(samples[i].squeeze(0), cmap='gray')\n",
    "            ax[i].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "generate_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de l'espace latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def loss_function(recon_x, x, mu, logvar, beta=1):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + beta * KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training and plotting function\n",
    "def train_and_plot(kl_weight):\n",
    "    model = ConvVAE(latent_dims).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        bce_loss = 0\n",
    "        kld_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mu, logvar = model(data)\n",
    "            loss, bce, kld = loss_function(x_recon, data, mu, logvar, kl_weight)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            bce_loss += bce.item()\n",
    "            kld_loss += kld.item()\n",
    "        \n",
    "        average_loss = epoch_loss / len(train_loader.dataset)\n",
    "        average_bce = bce_loss / len(train_loader.dataset)\n",
    "        average_kld = kld_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}: Average Loss: {average_loss:.4f}, BCE: {average_bce:.4f}, KLD: {average_kld:.4f}')\n",
    "    \n",
    "    # Plot latent space\n",
    "    plot_latent_space(model, kl_weight)\n",
    "\n",
    "# Function to plot latent space\n",
    "def plot_latent_space(model, kl_weight):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=10000, shuffle=False)\n",
    "        data, labels = next(iter(test_loader))\n",
    "        data = data.to(device)\n",
    "        mu, logvar = model.encode(data)\n",
    "        z = mu  # For visualization, we use the mean\n",
    "        z = z.cpu().numpy()\n",
    "        labels = labels.numpy()\n",
    "        \n",
    "        plt.figure(figsize=(8,6))\n",
    "        scatter = plt.scatter(z[:, 0], z[:, 1], c=labels, cmap='tab10', alpha=0.7)\n",
    "        plt.colorbar(scatter, ticks=range(10))\n",
    "        plt.clim(-0.5, 9.5)\n",
    "        plt.title(f'Latent Space with KL Weight = {kl_weight}')\n",
    "        plt.xlabel('Z1')\n",
    "        plt.ylabel('Z2')\n",
    "        plt.show()\n",
    "\n",
    "# Run training and plotting for different KL weights\n",
    "for kl_weight in kl_weights:\n",
    "    print(f'\\nTraining VAE with KL Weight = {kl_weight}')\n",
    "    train_and_plot(kl_weight)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
